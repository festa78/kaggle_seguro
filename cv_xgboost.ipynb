{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "05d70aa9-df4b-4612-8e9b-951fd4cb6cc6",
    "_uuid": "595e6a59ba01a71e6a43dba0118f405d524fb4c2"
   },
   "outputs": [],
   "source": [
    "# load Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "1d235f03-1ccf-498c-a7ae-b86be06498d1",
    "_uuid": "7e8f9531f8895239a26aef3646986ee5eb5337f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (595212, 59)\n",
      "test size: (892816, 58)\n",
      "have the same columns? True\n"
     ]
    }
   ],
   "source": [
    "### load data\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print('train size:', train_df.shape)\n",
    "print('test size:', test_df.shape)\n",
    "print('have the same columns?', all(train_df.drop('target', axis=1).columns == test_df.columns))\n",
    "train_df_org = train_df\n",
    "test_df_org = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 595212 rows and 59 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   0          0              1          8              1              0   \n",
       "1   1          4              2          5              1              0   \n",
       "2   2          5              1          3              0              0   \n",
       "3   3          0              1          6              0              0   \n",
       "4   4          5              1          7              0              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin       ...        \\\n",
       "0              0              1              0              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              1              0              0              0       ...         \n",
       "4              0              0              0              1       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           1           1           1          12               0   \n",
       "1           2           0           3          10               0   \n",
       "2           4           0           2           4               0   \n",
       "3           5           1           0           5               1   \n",
       "4           4           0           0           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               0               1               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               1               1               0               0   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###data cleansing\n",
    "# remove duplicatives if exists\n",
    "# wrt rows\n",
    "train_df = train_df.drop_duplicates()\n",
    "# wrt columns (get recursion error)\n",
    "#train_df = train_df.T.drop_duplicates().T\n",
    "\n",
    "rows = train_df.shape[0]\n",
    "columns = train_df.shape[1]\n",
    "print(\"The train dataset contains {0} rows and {1} columns\".format(rows, columns))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant values\n",
    "train_df = train_df.loc[:, (train_df != train_df.iloc[0]).any()]\n",
    "test_df = test_df.loc[:, train_df.drop('target', axis=1).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan exists in train?: True\n",
      "nan exists in test?: True\n"
     ]
    }
   ],
   "source": [
    "# fill nan by median\n",
    "train_df = train_df.replace(-1, np.NaN)\n",
    "test_df = test_df.replace(-1, np.NaN)\n",
    "print('nan exists in train?:', train_df.isnull().any().any())\n",
    "print('nan exists in test?:', test_df.isnull().any().any())\n",
    "train_median = train_df.drop('target', axis=1).median()\n",
    "train_df = train_df.fillna(train_median)\n",
    "test_df = test_df.fillna(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train float: 20\n",
      "train int: 37\n",
      "test float: 20\n",
      "test int: 37\n"
     ]
    }
   ],
   "source": [
    "# separate data\n",
    "train_y = train_df.loc[:, 'target']\n",
    "train_id = train_df.loc[:, 'id']\n",
    "train_df = train_df.drop(['target', 'id'], axis=1)\n",
    "train_df_float = train_df.select_dtypes(include=['float64'])\n",
    "train_df_int = train_df.select_dtypes(include=['int64'])\n",
    "test_id = test_df.loc[:, 'id']\n",
    "test_df = test_df.drop('id', axis=1)\n",
    "test_df_float = test_df.select_dtypes(include=['float64'])\n",
    "test_df_int = test_df.select_dtypes(include=['int64'])\n",
    "print('train float:', len(train_df_float.columns))\n",
    "print('train int:', len(train_df_int.columns))\n",
    "print('test float:', len(test_df_float.columns))\n",
    "print('test int:', len(test_df_int.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 57)\n",
      "(892816, 57)\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "train_df_float_mean = train_df_float.mean()\n",
    "train_df_float_std = train_df_float.std()\n",
    "train_df_float_norm = (train_df_float - train_df_float_mean) / (train_df_float_std + 1.e-9)\n",
    "test_df_float_norm = (test_df_float - train_df_float_mean) / (train_df_float_std + 1.e-9)\n",
    "\n",
    "train_df_norm = pd.concat((train_df_float_norm, train_df_int), axis=1)\n",
    "test_df_norm = pd.concat((test_df_float_norm, test_df_int), axis=1)\n",
    "print(train_df_norm.shape)\n",
    "print(test_df_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini score\n",
    "def gini(solution, submission):\n",
    "    df = zip(solution, submission, range(len(solution)))\n",
    "    df = sorted(df, key=lambda x: (x[1],-x[2]), reverse=True)\n",
    "    rand = [float(i+1)/float(len(df)) for i in range(len(df))]\n",
    "    totalPos = float(sum([x[0] for x in df]))\n",
    "    cumPosFound = [df[0][0]]\n",
    "    for i in range(1,len(df)):\n",
    "        cumPosFound.append(cumPosFound[len(cumPosFound)-1] + df[i][0])\n",
    "    Lorentz = [float(x)/totalPos for x in cumPosFound]\n",
    "    Gini = [Lorentz[i]-rand[i] for i in range(len(df))]\n",
    "    return sum(Gini)\n",
    "\n",
    "def normalized_gini(solution, submission):\n",
    "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n",
    "    return normalized_gini\n",
    "\n",
    "# Normalized Gini Scorer\n",
    "gini_scorer = metrics.make_scorer(normalized_gini, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtarget, cv_folds=5, early_stopping_rounds=50):    \n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(dtrain.values, label=dtarget)\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                      metrics=gini_scorer, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "    print('cvresult:', cvresult)\n",
    "    alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    # Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtarget, eval_metric=gini_scorer)\n",
    "        \n",
    "    # Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "        \n",
    "    # Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.mean_squared_error(dtarget, dtrain_predictions))\n",
    "    feat_imp = xgb.plot_importance(alg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter tuning of xgboost\n",
    "# start from default setting\n",
    "xgb0 = \\\n",
    "    xgb.XGBRegressor(max_depth=10,                    \n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=1000,\n",
    "                     n_jobs=4,\n",
    "                     gamma=0,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=1,\n",
    "                     colsample_bytree=1,\n",
    "                     scale_pos_weight=1,\n",
    "                     seed=27)\n",
    "xgb0.fit(train_df_norm, train_y, eval_metric=gini_scorer)\n",
    "predict_y = xgb0.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./xgb0_submission.csv', index=False)   #LB0.269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimator tuning\n",
    "xgb1 = xgb0\n",
    "modelfit(xgb1, train_df_norm, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_estimators:', xgb1.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "param_test1 = {\n",
    "    'max_depth':range(3,10,1),\n",
    "    'min_child_weight':range(1,6,1)\n",
    "}\n",
    "\n",
    "gsearch1 = \\\n",
    "    GridSearchCV(estimator=xgb.XGBRegressor(max_depth=3,\n",
    "                                            learning_rate=0.1,\n",
    "                                            n_estimators=xgb1.n_estimators,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=0,\n",
    "                                            min_child_weight=1,    \n",
    "                                            subsample=1,\n",
    "                                            colsample_bytree=1,\n",
    "                                            scale_pos_weight=1,\n",
    "                                            seed=27),\n",
    "                 param_grid=param_test1,\n",
    "                 scoring=gini_scorer,\n",
    "                 n_jobs=4,\n",
    "                 iid=False,\n",
    "                 cv=5)\n",
    "gsearch1.fit(train_df_norm, train_y, eval_metric=gini_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = gsearch1.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./gsearch1_submission.csv', index=False)   #LB0.261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on gamma\n",
    "param_test2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "gsearch2 = \\\n",
    "    GridSearchCV(estimator=xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                            learning_rate=0.1,\n",
    "                                            n_estimators=xgb1.n_estimators,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=0,\n",
    "                                            min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                            subsample=1,\n",
    "                                            colsample_bytree=1,\n",
    "                                            scale_pos_weight=1,\n",
    "                                            seed=27),\n",
    "                 param_grid=param_test2,\n",
    "                 scoring=gini_scorer,\n",
    "                 n_jobs=4,\n",
    "                 iid=False,\n",
    "                 cv=5)\n",
    "gsearch2.fit(train_df_norm, train_y, eval_metric=gini_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = gsearch2.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./gsearch2_submission.csv', index=False)   #LB0.261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate boosting round\n",
    "xgb2 = \\\n",
    "    xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                                learning_rate=0.1,\n",
    "                                                n_estimators=1000,\n",
    "                                                n_jobs=4,\n",
    "                                                gamma=gsearch2.best_params_['gamma'],\n",
    "                                                min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                                subsample=1,\n",
    "                                                colsample_bytree=1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=27)\n",
    "modelfit(xgb2, train_df_norm, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_estimators:', xgb2.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample, colsample_bytree\n",
    "param_test3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "gsearch3 = \\\n",
    "    GridSearchCV(estimator=xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                            learning_rate=0.1,\n",
    "                                            n_estimators=xgb2.n_estimators,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=gsearch2.best_params_['gamma'],\n",
    "                                            min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                            subsample=1,\n",
    "                                            colsample_bytree=1,\n",
    "                                            scale_pos_weight=1,\n",
    "                                            seed=27),\n",
    "                 param_grid=param_test3,\n",
    "                 scoring=gini_scorer,\n",
    "                 n_jobs=4,\n",
    "                 iid=False,\n",
    "                 cv=5)\n",
    "gsearch3.fit(train_df_norm, train_y, eval_metric=gini_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = gsearch3.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./gsearch3_submission.csv', index=False)   #LB0.244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on reg_alpha\n",
    "param_test4 = {\n",
    " 'reg_alpha':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "gsearch4 = \\\n",
    "    GridSearchCV(estimator=xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                            learning_rate=0.1,\n",
    "                                            n_estimators=xgb2.n_estimators,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=gsearch2.best_params_['gamma'],\n",
    "                                            min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                            subsample=gsearch3.best_params_['subsample'],\n",
    "                                            colsample_bytree=gsearch3.best_params_['colsample_bytree'],\n",
    "                                            scale_pos_weight=1,\n",
    "                                            reg_alpha=0.005,\n",
    "                                            seed=27),\n",
    "                 param_grid=param_test4,\n",
    "                 scoring=gini_scorer,\n",
    "                 n_jobs=4,\n",
    "                 iid=False,\n",
    "                 cv=5)\n",
    "gsearch4.fit(train_df_norm, train_y, eval_metric=gini_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = gsearch4.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./gsearch4_submission.csv', index=False)   #LB0.244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate boosting round\n",
    "xgb3= \\\n",
    "    xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                            learning_rate=0.1,\n",
    "                                            n_estimators=1000,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=gsearch2.best_params_['gamma'],\n",
    "                                            min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                            subsample=gsearch3.best_params_['subsample'],\n",
    "                                            colsample_bytree=gsearch3.best_params_['colsample_bytree'],\n",
    "                                            scale_pos_weight=1,\n",
    "                                            reg_alpha=gsearch4.best_params_['reg_alpha'],\n",
    "                                            seed=27)\n",
    "modelfit(xgb3, train_df_norm, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_estimators:', xgb3.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate boosting round w/ reduced lr and increased estimators\n",
    "xgb4= \\\n",
    "    xgb.XGBRegressor(max_depth=gsearch1.best_params_['max_depth'],\n",
    "                                            learning_rate=0.01,\n",
    "                                            n_estimators=5000,\n",
    "                                            n_jobs=4,\n",
    "                                            gamma=gsearch2.best_params_['gamma'],\n",
    "                                            min_child_weight=gsearch1.best_params_['min_child_weight'],    \n",
    "                                            subsample=gsearch3.best_params_['subsample'],\n",
    "                                            colsample_bytree=gsearch3.best_params_['colsample_bytree'],\n",
    "                                            scale_pos_weight=1,\n",
    "                                            reg_alpha=gsearch4.best_params_['reg_alpha'],\n",
    "                                            seed=27)\n",
    "modelfit(xgb4, train_df_norm, train_y, eval_metric=gini_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n_estimators:', xgb4.n_estimators)\n",
    "predict_y = xgb4.predict(test_df_norm)\n",
    "predict_submit = pd.concat((test_id, pd.DataFrame(data=predict_y, columns=['target'])), axis=1)\n",
    "predict_submit.to_csv('./xgb4_submission.csv', index=False)   #LB0.236"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
